\documentclass[12pt,a4paper,titlepage]{article}
\title{Sound Event Detection con la tecnica del “few-shot learning“} 
\author{Matteo Orlandini}
\date{\today}

\usepackage[english, italian]{babel} %the last declared language is the one used in the document
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{booktabs} %toprule, midrule, bottomrule
\usepackage{subfig}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{siunitx}
\usepackage{amsmath}
\usepackage{xcolor}

\colorlet{punct}{red!60!black}
\definecolor{background}{HTML}{EEEEEE}
\definecolor{delim}{RGB}{20,105,176}
\colorlet{numb}{magenta!60!black}

\lstdefinelanguage{json}{
	basicstyle=\normalfont\ttfamily,
	%numbers=left,
	tabsize=4,
	numberstyle=\scriptsize,
	stepnumber=1,
	numbersep=8pt,
	showstringspaces=false,
	breaklines=true,
	frame=lines,
	%backgroundcolor=\color{background},
	literate=
	%*{0}{{{\color{numb}0}}}{1}
	%{1}{{{\color{numb}1}}}{1}
	%{2}{{{\color{numb}2}}}{1}
	%{3}{{{\color{numb}3}}}{1}
	%{4}{{{\color{numb}4}}}{1}
	%{5}{{{\color{numb}5}}}{1}
	%{6}{{{\color{numb}6}}}{1}
	%{7}{{{\color{numb}7}}}{1}
	%{8}{{{\color{numb}8}}}{1}
	%{9}{{{\color{numb}9}}}{1}
	%{:}{{{\color{punct}{:}}}}{1}
	{,}{{{\color{punct}{,}}}}{1}
	{\{}{{{\color{delim}{\{}}}}{1}
	{\}}{{{\color{delim}{\}}}}}{1}
	{[}{{{\color{delim}{[}}}}{1}
	{]}{{{\color{delim}{]}}}}{1},
 	morekeywords = {folder, reader_name, word, frequency, start, end},
	keywordstyle=\color{blue},
	commentstyle=\color{black},
}

\usepackage{color}
\definecolor{gray}{rgb}{0.4,0.4,0.4}
\definecolor{darkblue}{rgb}{0.0,0.0,0.6}
\definecolor{cyan}{rgb}{0.0,0.6,0.6}

\lstset{literate=% Allow for German characters in lstlistings.
	{Ö}{{\"O}}1
	{Ä}{{\"A}}1
	{Ü}{{\"U}}1
	{ß}{{\ss}}2
	{ü}{{\"u}}1
	{ä}{{\"a}}1
	{ö}{{\"o}}1
}

\lstdefinelanguage{XML}
{
	frame=lines,
	morestring=[b]",
	%morestring=[s]{>}{<},
	%morecomment=[s]{<?}{?>},
	stringstyle=\color{darkblue},
	identifierstyle=\color{cyan},
	keywordstyle=\bfseries\color{black},
	morekeywords={key, value, group, text, pronunciation, start, end}
	moreidentifier = {article, meta, link, prop, d, extra, t, s, n, ignored},
	%backgroundcolor=\color{background},
}

%\usepackage[latin1]{inputenc} %l'ho messo io (Jacopo)
%inizio impostazioni bibliografia
\usepackage[autostyle,italian=guillemets]{csquotes} 
%autostyle adatta lo stile delle citazioni alla lingua corrente del documento;
%italian=guillemets racchiude automaticamente tra virgolette caporali
%i campi che prevedono le virgolette;
\usepackage[backend=biber, style=numeric, citestyle=numeric,maxcitenames=99,maxbibnames = 99]{biblatex}
%backend=biber dice a biblatex che s’intende usare Biber come motore bibliografico
%style:numeric Anno di pubblicazione: in fondo al riferimento.
%citestyle=numeric Riferimento: numerico ([1], [2], eccetera).
%fine impostazioni bibliografia

\usepackage{float}
\usepackage{hyperref}
\hypersetup{
%	bookmarks=true,         % show bookmarks bar?
	unicode=false,          % non-Latin characters in Acrobat’s bookmarks
	pdftoolbar=true,        % show Acrobat’s toolbar?
	pdfmenubar=true,        % show Acrobat’s menu?
	pdffitwindow=false,     % window fit to page when opened
	pdfstartview={FitH},    % fits the width of the page to the window
	%pdftitle={Relazione di Reti di Sensori Wireless per IOT},    % title
	pdfauthor={Matteo Orlandini},     % author
	pdfsubject= {Sound Event Detection con la tecnica del few-shot learning},   % subject of the document
	pdfcreator={Matteo Orlandini},   % creator of the document
	%pdfproducer={Producer}, % producer of the document
	pdfpagemode={UseOutlines},
	%bookmarksopen,
	pdfstartview={FitH},
	colorlinks=false,       % false: boxed links; true: colored links
	linkcolor={red},
	citecolor={green},
	urlcolor={cyan}
} 

\renewcommand{\lstlistingname}{Codice}

\addbibresource{Bibliografia.bib}

\newcommand{\CoverName}{Cover}

\begin{document}

\begin{titlepage}
	
	\centering
	\includegraphics[width=.2\textwidth]{Immagini/univpmlogo}\par\vspace{1cm}
	{\scshape\LARGE Università Politecnica delle Marche\par}
	\vspace{1cm}
	{\scshape\Large Digital Adaptive Circuits And Learning Systems\par}
	\vspace{1.5cm}
	{\huge\bfseries Sound Event Detection con la tecnica del  ``\emph{few-shot learning}''  \par}
	\vspace{2cm}
	{\Large\itshape Matteo Orlandini e Jacopo Pagliuca\par}
	\vfill
	Prof. Stefano \textsc{Squartini}\\
	Dott.ssa Michela \textsc{Cantarini}
	
	\vfill
	
	% Bottom of the page
	{\large \today\par}
\end{titlepage}

\thispagestyle{empty}
\tableofcontents
\clearpage

%\newpage
\setcounter{page}{1}

\section{Introduzione}
\label{section:Introduzione}
\clearpage

\section{Few-shot learning}
\label{section:Few-shot}
(https://www.borealisai.com/en/blog/tutorial-2-few-shot-learning-and-meta-learning-i/)
\subsection{Introduzione}
Gli esseri umani possono riconoscere nuove classi di oggetti da pochissime istanze. Tuttavia, la maggior parte delle tecniche di apprendimento automatico richiedono migliaia di esempi per ottenere prestazioni simili. L'obiettivo dell'apprendimento a breve termine è classificare i nuovi dati dopo aver visto solo pochi esempi di allenamento. All'estremo, potrebbe esserci solo un singolo esempio di ogni classe (one shot learning). In pratica, l'apprendimento a breve termine è utile quando è difficile trovare esempi di training (ad es. casi di una malattia rara) o quando il costo dell'etichettatura dei dati è elevato.

L'apprendimento a pochi colpi viene solitamente studiato utilizzando la classificazione N-way-K-shot. Qui, miriamo a discriminare tra N classi con K esempi di ciascuno. Una tipica dimensione del problema potrebbe essere quella di discriminare tra N=10 classi con solo K=5 campioni da ciascuno da cui allenarsi. Non possiamo addestrare un classificatore usando metodi convenzionali qui; qualsiasi algoritmo di classificazione moderno dipenderà da molti più parametri rispetto agli esempi di addestramento e generalizzerà male.
Se i dati non sono sufficienti per ridurre il problema, una possibile soluzione è acquisire esperienza da altri problemi simili. A tal fine, la maggior parte degli approcci caratterizza l'apprendimento a breve termine con un problema di meta-apprendimento.

\subsection{The meta learning framework}
Nel framework di apprendimento classico, impariamo come classificare dai dati di addestramento e valutiamo i risultati utilizzando i dati di test. Nel quadro del meta-apprendimento, \textit{impariamo come imparare} a classificare in base a una serie di \textit{training task} e valutiamo utilizzando una serie di test task; In altre parole, usiamo un insieme di problemi di classificazione per aiutare a risolvere altri insiemi non correlati.
Qui, ogni attività imita lo scenario few-shot, quindi per la classificazione N-way-K-shot, ogni attività include N classi con K esempi di ciascuno. Questi sono noti come support set per il task e vengono utilizzati per apprendere come risolvere questa task. Inoltre, esistono ulteriori esempi delle stesse classi, note come set di query, utilizzate per valutare le prestazioni del task corrente. Ogni task può essere completamente unico; potremmo non vedere mai le classi di un task in nessuno degli altri. L'idea è che il sistema veda ripetutamente istanze (task) durante l'addestramento che corrispondono alla struttura dell'attività finale di few-shot, ma che contengono classi diverse.
Ad ogni fase del meta-apprendimento, aggiorniamo i parametri del modello in base ad un training task selezionato casualmente. La funzione di loss è determinata dalle prestazioni di classificazione sul set di query del task, in base alla conoscenza acquisita dal relativo set di supporto. Poiché la rete viene sottoposta ad un compito diverso in ogni fase temporale, deve imparare a discriminare le classi di dati in generale, piuttosto che un particolare sottoinsieme di classi.

Per valutare le prestazioni in pochi colpi, utilizziamo una serie di attività di test. Ciascuno contiene solo classi invisibili che non erano in nessuna delle attività di formazione. Per ciascuno, misuriamo le prestazioni sul set di query in base alla conoscenza del loro set di supporto.

\subsection{Approcci al meta-apprendimento}
Gli approcci al meta-apprendimento sono diversi e non c'è consenso sull'approccio migliore. Tuttavia, esistono tre famiglie distinte, ognuna delle quali sfrutta un diverso tipo di conoscenza a priori:
\begin{itemize}
	\item Conoscenze a priori sulla somiglianza: apprendiamo degli embedding nei training task che tendono a separare classi diverse anche quando non sono visibili.
	\item Conoscenze a priori sull'apprendimento: utilizziamo le conoscenze a priori per vincolare l'algoritmo di apprendimento a scegliere parametri che generalizzino bene da pochi esempi.
	\item Conoscenza a priori dei dati: sfruttiamo le conoscenze a priori sulla struttura e la variabilità dei dati e questo ci consente di apprendere modelli praticabili da pochi esempi.
\end{itemize}

\clearpage

\section{Dataset Spoken Wikipedia Corpora}
\label{sec:spoken_wikipedia_corpora}
Il progetto Spoken Wikipedia unisce lettori volontari di articoli di Wikipedia. Centinaia di articoli in inglese, tedesco e olandese sono disponibili per gli utenti che non sono in grado o non vogliono leggere la versione scritta dell'articolo. Il dataset trasforma i file audio in un corpus allineato nel tempo, rendendolo accessibile per la ricerca.\cite{minining_spoken_wikipedia}

Questo corpus ha diverse caratteristiche importanti:
\begin{itemize}
	\item centinaia di ore di audio allineato
	\item lettori eterogenei
	\item diversi argomenti
	\item genere testuale ben studiato
	\item le annotazioni delle parole possono essere mappate all'html originale
	\item allineamenti a livello di fonema
\end{itemize}

Ogni articolo è suddiviso in sezioni, frasi e token. Ogni token è normalizzato e la normalizzazione è allineata all'audio.

INSERIRE SCHEMA SWC.RNC!!

\subsection{Annotazioni}
\label{subsec:annotazioni}
\begin{lstlisting}[language=xml,firstnumber=1, caption=Metadati delle annotazioni delle parole in un audio, label=metadati_annotazioni,captionpos=b, basicstyle=\tiny]
<article>
<meta>
<link key="DC.conformsto" value="http://nats.gitlab.io/swc/schema/swc-1.0.rnc"/>
<prop key="DC.creator" value="Spoken Wikipedia Corpus Collection Software"/>
<prop key="DC.publisher" value="Universität Hamburg"/>
<link key="DC.reference" value="http://nbn-resolving.de/urn:nbn:de:gbv:18-228-7-2209"/>
<prop key="DC.type" value="dataset"/>
<prop key="DC.license" value="CC-BY-SA"/>
<prop key="DC.title" value="(I Can't Get No) Satisfaction"/>
<prop key="DC.language" value="en"/>
<prop key="DC.identifier" value="(I_Can%27t_Get_No)_Satisfaction"/>
<prop key="DC.date.read" value="2005-04-20 00:00:00"/>
<link key="DC.source" value="https://en.wikipedia.org/wiki/(I_Can%27t_Get_No)_Satisfaction"/>
<prop key="DC.source.wikiID" value="7156876"/>
<prop key="DC.source.revision" value="786995193"/>
<link key="DC.source.text" value="https://en.wikipedia.org/w/index.php?title=(I Can't Get No) Satisfaction&oldid=13424379"/>
<link key="DC.source.audio" value="https://upload.wikimedia.org/wikipedia/commons/3/38/En-%28I_Can%27t_Get_No%29_Satisfaction-article.oga" group="audio1"/>
<prop key="DC.source.audio.offset" value="0.0" group="audio1"/>
<link key="DC.source.audio.page" value="https://en.wikipedia.org/w/index.php?title=File%3aEn-(I_Can%27t_Get_No)_Satisfaction-article.oga" group="audio1"/>
<link key="DC.source.audio.date" value="2007-09-14 19:28:20" group="audio1"/>
<prop key="reader.name" value="the Epopt"/>
<prop key="processing.step" value="tokenize" group="tokenize"/>
<prop key="processing.step.date" value="2017-08-10T07:42:18.769+02:00[Europe/Berlin]" group="tokenize"/>
<prop key="processing.step.options" value="Namespace(output=articles/(I_Can%27t_Get_No)_Satisfaction/tokenized.swc, all_sections=false, null_normalize=false, raw_output=null, subparser_name=tokenize, lang=en, no_introduction=false, article_dir=articles/(I_Can%27t_Get_No)_Satisfaction)" group="tokenize"/>
<prop key="processing.step.git.commit.id" value="7431dbf93f212ad828208abaf8f518fb8de11ff3" group="tokenize"/>
<prop key="processing.step.git.commit.time" value="09.08.2017 @ 15:21:55 CEST" group="tokenize"/>
<prop key="processing.step" value="align" group="align"/>
<prop key="processing.step.date" value="2017-08-11T14:56:44.948+02:00[Europe/Berlin]" group="align"/>
<prop key="processing.step.options" value="Namespace(output=articles/(I_Can%27t_Get_No)_Satisfaction/aligned.swc, transcript=articles/(I_Can%27t_Get_No)_Satisfaction/tokenized.swc, g2p=../model_en/model.fst.ser, phone=false, subparser_name=align, dict=../model_en/empty.dic, acoustic_model=../model_en/, audio=articles/(I_Can%27t_Get_No)_Satisfaction/audio.wav)" group="align"/>
<prop key="processing.step.git.commit.id" value="7431dbf93f212ad828208abaf8f518fb8de11ff3" group="align"/>
<prop key="processing.step.git.commit.time" value="09.08.2017 @ 15:21:55 CEST" group="align"/>
</meta>
\end{lstlisting}

\begin{lstlisting}[language=xml,firstnumber=1, caption=Annotazioni delle parole in un audio, label=annotazioni,captionpos=b, basicstyle=\tiny]
<d>
<extra text="(I Can't Get No) SatisfactionFrom wikipedia, the free encyclopedia at e n dot wikipedia dot org.">
<s text="(I Can't Get No) SatisfactionFrom wikipedia, the free encyclopedia at e n dot wikipedia dot org.">
<t text="("/>
<t text="I">
<n pronunciation="I" start="660" end="870"/>
</t>
<t text="Can't">
<n pronunciation="Cant" start="870" end="1250"/>
</t>
<t text="Get">
<n pronunciation="Get" start="1280" end="1550"/>
</t>
<t text="No">
<n pronunciation="No" start="1550" end="1870"/>
</t>
<t text=")"/>
<t text="SatisfactionFrom">
<n pronunciation="SatisfactionFrom" start="1870" end="3010"/>
</t>
\end{lstlisting}

\subsection{Lettori}
\label{subsec:lettori}

\begin{lstlisting}[language=json,firstnumber=1, caption=Formato JSON dei lettori, label=JSON_lettori,captionpos=b]
{
	"reader_name": "the epopt",
	"folder": [
		"(I_Can%27t_Get_No)_Satisfaction",
		"Ceremonial_ship_launching",
		"Limerence",
		"Revolt_of_the_Admirals",
		"Ship_commissioning"
	]
},
{
	"reader_name": "wodup",
	"folder": [
		"0.999..%2e",
		"Execution_by_elephant",
		"Hell_Is_Other_Robots",
		"Tom_Bosley",
		"Truthiness"
	]
},
\end{lstlisting}

\subsection{Parole}
\label{subsec:parole}

\begin{lstlisting}[language=json,firstnumber=1, caption=Formato JSON delle parole allineate, label=JSON_parole,captionpos=b]
[
{
	"word": "i",
	"frequency": 12,
	"start": [
		660,
		8800,
		115050,
		116300,
		117910,
		228560,
		273900,
		497150,
		518270,
		534740,
		543420,
		589280
	],
	"end": [
		870,
		8940,
		115240,
		116360,
		118020,
		228690,
		274000,
		497340,
		518520,
		534860,
		543700,
		589360
	]
},
\end{lstlisting}

\clearpage
\nocite{*}
%Il comando \printbibliography produce la sezione bibliografica con relativi
%titolo e testatina. Per mandarne il relativo titolo nell’indice generale si
%usa l’istruzione:
\printbibliography

\end{document} 